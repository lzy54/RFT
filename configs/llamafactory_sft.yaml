# configs/llamafactory_sft.yaml

### =========================
### Model
### =========================
model_name_or_path: Qwen/Qwen3-7B
trust_remote_code: true

### =========================
### Stage / Training
### =========================
stage: sft
do_train: true
finetuning_type: full
gradient_checkpointing: true

### =========================
### Dataset
### =========================
# 你 run_build 产出：data/rft_sft.jsonl
dataset: rft_sft
dataset_dir: ./data
template: sharegpt

# 不裁剪 thinking：给足长度（根据你机器/显存可改 4096/8192/16384）
cutoff_len: 8192
max_samples: null

### =========================
### Output & Logging
### =========================
output_dir: outputs/qwen3_rft_sft
overwrite_output_dir: true
logging_steps: 10
save_steps: 200
save_total_limit: 2
report_to: none

### =========================
### Optimization
### =========================
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 2e-5
num_train_epochs: 1
lr_scheduler_type: cosine
warmup_ratio: 0.03

### =========================
### Precision
### =========================
fp16: true

### =========================
### Eval (optional)
### =========================
do_eval: false
